name: mediaqa_emb
dataset:
  proto: TextDatasetRNN
  root: data/new_mediaca
  src: findings.tok
  tgt: impression.tok
  max_len: 80
  eval_max_len: 200

model:
  proto: RNN
  src_emb: data/new_mediaca/src_biowordvec.npy
  tgt_emb: data/new_mediaca/tgt_biowordvec.npy

  encoder:
    proto: TextEncoder
    rnn_type: GRU
    input_size: 200
    hidden_size: 320
    n_vocab: 5804
    num_layers: 2
    bidirectional: True
    proj_dim: False
    proj_activ: None
    layer_norm: False
    dropout_rnn: 0
    dropout_emb: 0.4
    dropout_ctx: 0.5

  decoder:
    proto: ConditionalDecoder
    input_size: 200
    hidden_size: 320
    n_vocab: 4447 # impression
    rnn_type: GRU
    tied_emb: True
    dec_init: zero
    dec_init_activ: tanh
    dec_init_size: None
    att_type: mlp
    att_activ: tanh
    att_bottleneck: hid
    att_temp: 1.0
    transform_ctx: True
    mlp_bias: False
    dropout_out: 0.5


train:
  proto: NMTTrainer
  device: cuda
  lr: 0.0004
  weight_decay: 0.00001 #1e-05
  batch_size: 64
  lr_decay_factor: 0.5
  lr_decay_patience: 2
  lr_min: 0.000001
  epochs: 99
  early_stop: 10
  eval_start: 0
  early_stop_metric: ROUGE

validator:
  proto: NMTValidator
  device: cuda
  batch_size: 16
  beam_width: 8
  splits: [indiana_dev]

ensemblor:
  proto: NMTEnsemblor
  device: cuda
  batch_size: 16
  beam_width: 8
#  splits: [indiana_dev]
  splits: [indiana_dev, indiana_test, stanford_test]
  mode: all # best,all
